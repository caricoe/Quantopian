"""
This is a demo algorithm to show folks how to conduct some rudimentary machine learning on Morningstar Fundamental data in the Quantopian IDE.
"""

##################################################
# Imports
##################################################

from __future__ import division
from collections import OrderedDict
import time

# Pipeline, Morningstar, and Quantopian Trading Functions
from quantopian.algorithm import attach_pipeline, pipeline_output, order_optimal_portfolio
from quantopian.pipeline import Pipeline, CustomFactor
from quantopian.pipeline.data import Fundamentals
from quantopian.pipeline.data.builtin import USEquityPricing
from quantopian.pipeline.filters import QTradableStocksUS
from quantopian.optimize import TargetWeights

# The basics
import pandas as pd
import numpy as np

# SKLearn :)
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree  import DecisionTreeRegressor

from sklearn.preprocessing import Imputer, StandardScaler

##################################################
# Globals
##################################################

num_holding_days = 6 # holding our stocks for five trading days.
days_for_fundamentals_analysis = 8

##################################################
# Initialize
##################################################

def initialize(context):
    """ Called once at the start of the algorithm. """
    context.max_leverage = 1.0
    context.max_pos_size = 0.045
    context.max_turnover = 0.9

    # Configure the setup
    set_commission(commission.PerShare(cost=0.001, min_trade_cost=0))
    set_asset_restrictions(security_lists.restrict_leveraged_etfs)

    # Schedule our function
    schedule_function(rebalance, date_rules.week_start(), time_rules.market_open(minutes=1))

    # Build the Pipeline
    attach_pipeline(make_pipeline(), 'my_pipeline')

##################################################
# Pipeline-Related Code
##################################################

class Predictor(CustomFactor):
    """ Defines our machine learning model. """

    # The factors that we want to pass to the compute function. We use an ordered dict for clear labeling of our inputs.
    factor_dict = OrderedDict([
              ('Open Price' , USEquityPricing.open),
              ('Volume' , USEquityPricing.volume),
              ('earning_yield' , Fundamentals.earning_yield), 
              ('sales_per_share' , Fundamentals.sales_per_share),
              ('basic_average_shares_earnings_reports' , Fundamentals.basic_average_shares_earnings_reports)
              ])

    columns = factor_dict.keys()
    inputs = factor_dict.values()

    # Run it.
    def compute(self, today, assets, out, *inputs):
        """ Through trial and error, I determined that each item in the input array comes in with rows as days and securities as columns. Most recent data is at the "-1" index. Oldest is at 0.

        !!Note!! In the below code, I'm making the somewhat peculiar choice  of "stacking" the data... you don't have to do that... it's just a design choice... in most cases you'll probably implement this without stacking the data.
        """

        ## Import Data and define y.
        inputs = OrderedDict([(self.columns[i] , pd.DataFrame(inputs[i]).fillna(method='ffill',axis=1).fillna(method='bfill',axis=1)) for i in range(len(inputs))]) # bring in data with some null handling.
        num_secs = len(inputs['Open Price'].columns)
        y = (np.log(inputs['Open Price']) - np.log(inputs['Open Price'].shift(num_holding_days))).shift(-num_holding_days-1).dropna(axis=0,how='all').stack(dropna=False)
        
        ## Get rid of our y value as an input into our machine learning algorithm.
        del inputs['Open Price']

        ## Munge X and y
        x = pd.concat([df.stack(dropna=False) for df in inputs.values()], axis=1)
        x = Imputer(strategy='median',axis=1).fit_transform(x) # fill nulls.
        y = np.ravel(Imputer(strategy='median',axis=1).fit_transform(y)) # fill nulls.
        scaler = StandardScaler()
        x = scaler.fit_transform(x) # demean and normalize

        
        ##model = RandomForestRegressor(n_estimators=50,random_state=0)
        
        ## Run Model
        #model = DecisionTreeRegressor() 
        model = LinearRegression()
         
        #model=AdaBoostRegressor(n_estimators=50, learning_rate=0.2,loss='exponential')
        
        model_x = x[:-num_secs*(num_holding_days+1),:]
        model.fit(model_x, y)

        out[:] = model.predict(x[-num_secs:,:])


def make_pipeline():

    universe = QTradableStocksUS()

    pipe = Pipeline(columns={'Model': Predictor(window_length=days_for_fundamentals_analysis, mask=universe)},screen = universe)

    return pipe

##################################################
# Execution Functions
##################################################

def rebalance(context,data):
    """ Execute orders according to our schedule_function() timing."""

    # Timeit!
    start_time = time.time()

    ## Run pipeline
    pipeline_output_df = pipeline_output('my_pipeline').dropna(how='any')
    
    todays_predictions = pipeline_output_df.Model

    # Demean pipeline scores
    target_weight_series = todays_predictions.sub(todays_predictions.mean())

    # Reweight scores to prepare for portfolio ordering.
    target_weight_series = target_weight_series/target_weight_series.abs().sum()

    order_optimal_portfolio(objective=TargetWeights(target_weight_series),constraints=[])

    # Print useful things. You could also track these with the "record" function.
    print 'Full Rebalance Computed Seconds: '+'{0:.2f}'.format(time.time() - start_time)
    print "Number of total securities trading: "+ str(len(target_weight_series[target_weight_series > 0]))
    print "Leverage: " + str(context.account.leverage)
